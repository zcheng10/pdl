#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize letterpaper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1.25in
\topmargin 1.25in
\rightmargin 1.25in
\bottommargin 1.25in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Theory
\end_layout

\begin_layout Subsection
Pinhole camera model
\end_layout

\begin_layout Standard
The most common imaging model used in computer vision is the pinhole camera
 model
\begin_inset Foot
status open

\begin_layout Plain Layout
David A.
 Forsyth and Jean Ponce (2003).
 Computer Vision, A Modern Approach.
 Prentice Hall.
 ISBN 0-12-379777-2.
\end_layout

\end_inset

, which is illustrated in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Pinhole-camera-model"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename pasted1.png
	lyxscale 70
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Pinhole-camera-model"

\end_inset

Pinhole camera model
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Without loss of generality, suppose the pinhole is located at 
\begin_inset Formula $\left(0,0,0\right)$
\end_inset

.
 Denote the position of an object by 
\begin_inset Formula $\vec{r}=\left(x,y,z\right)$
\end_inset

, its velocity by 
\begin_inset Formula $\vec{v}=\left(v_{x},v_{y},v_{z}\right)$
\end_inset

, and its acceleration by 
\begin_inset Formula $\vec{a}=\left(a_{x},a_{y},a_{z}\right)$
\end_inset

.
 The screen on which the image is captured is located at a vector 
\begin_inset Formula $\vec{h_{s}}=h_{s}\hat{h_{0}}$
\end_inset

 from the origin.
 The screen coordinates basic vectors are 
\begin_inset Formula $\hat{h_{0}}$
\end_inset

, 
\begin_inset Formula $\hat{h}_{1}$
\end_inset

 and 
\begin_inset Formula $\hat{h}_{2}$
\end_inset

.
 That is, 
\begin_inset Formula $<\hat{h_{0}},\hat{h_{1}},\hat{h_{2}}>$
\end_inset

 also form a right-hand coordinate system.
 Note that
\begin_inset Formula 
\begin{equation}
\hat{h_{0}}\perp\hat{h_{1}}\perp\hat{h_{2}}
\end{equation}

\end_inset


\begin_inset Formula 
\begin{equation}
\hat{|h_{0}}|=|\hat{h_{1}}|=\hat{|h_{2}}|=1
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The screen plane is given by
\begin_inset Formula 
\begin{equation}
h_{s}\hat{h_{0}}+a\hat{h_{1}}+b\hat{h_{2}},\hspace{1em}a,b\in R
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Then the projection of 
\begin_inset Formula $\vec{r}$
\end_inset

 on the screen, which is the image of the object, 
\begin_inset Formula $\vec{p}=\left(a,b\right)$
\end_inset

, is given by
\begin_inset Formula 
\begin{equation}
-k\vec{r}=h_{s}\hat{h_{0}}+a\vec{h_{1}}+b\vec{h_{2}}\label{eq:screen-proj}
\end{equation}

\end_inset

where 
\begin_inset Formula $k$
\end_inset

 is the distance of the object from the pinhole and 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 are the 
\begin_inset Quotes eld
\end_inset

screen coordinates
\begin_inset Quotes erd
\end_inset

 of its image.
 
\begin_inset Formula 
\begin{equation}
\left(\vec{r},\hat{h_{1}},\hat{h_{2}}\right)\left(\begin{array}{c}
k\\
a\\
b
\end{array}\right)=-h_{s}\hat{h_{0}}
\end{equation}

\end_inset

or
\begin_inset Formula 
\[
\left(\hat{h_{1}},\hat{h_{2}},\vec{r}\right)\left(\begin{array}{c}
a\\
b\\
k
\end{array}\right)=-h_{s}\hat{h_{0}}
\]

\end_inset


\end_layout

\begin_layout Standard
Define 
\begin_inset Formula 
\begin{equation}
C^{-1}=\left(\hat{h_{1}},\hat{h_{2}},\vec{r}\right)^{-1}
\end{equation}

\end_inset

as the inverse camera matrix.
 The screen coordinates of the object 
\begin_inset Formula $\left(a,b\right)$
\end_inset

, as well as its distance 
\begin_inset Formula $k$
\end_inset

 from the pinhole, are given by
\begin_inset Formula 
\begin{equation}
\underline{\left(\begin{array}{c}
a\\
b\\
k
\end{array}\right)=-C^{-1}h_{s}\hat{h_{0}}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
The characteristics of the screen coordinate system
\end_layout

\begin_layout Standard
The world coordinates are denoted by 
\begin_inset Formula $\left(\hat{x},\hat{y},\hat{z}\right)$
\end_inset

, where 
\begin_inset Formula $\hat{z}$
\end_inset

 is the upward direction and 
\begin_inset Formula $\left(\hat{x},\hat{y}\right)$
\end_inset

 spans the ground.
 In the real world situations that we hope to analyze, not only do the objects
 move, but the camera also moves simultaneously.
 Therefore, 
\begin_inset Formula $<\hat{h_{0}},\hat{h_{1}},\hat{h_{2}}>$
\end_inset

 translates and rotates around the pinhole, and the pinhole also moves.
 In typical scenarios, the camera stands vertically, so 
\begin_inset Formula $\vec{h_{2}}$
\end_inset

 is close to vertical, the angle between them being 
\begin_inset Formula $\theta$
\end_inset

.
 Then 
\begin_inset Formula 
\begin{equation}
\hat{h_{2}}\cdot\hat{z}=\cos\theta\approx1
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
The solution to the imaging equation
\end_layout

\begin_layout Standard
In Eq.
 (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:screen-proj"
plural "false"
caps "false"
noprefix "false"

\end_inset

)
\begin_inset Formula 
\[
k\vec{r}+h_{s}\hat{h_{0}}+a\vec{h_{1}}+b\vec{h_{2}}=0
\]

\end_inset

Multiplying the equation by 
\begin_inset Formula $\hat{h_{i}}$
\end_inset

 for 
\begin_inset Formula $i=0,1,2$
\end_inset

, noting that 
\begin_inset Formula 
\[
\hat{h}_{i}\cdot\hat{h}_{j}=\begin{cases}
0 & i\ne j\\
1 & i=j
\end{cases}
\]

\end_inset

We get 
\begin_inset Formula 
\[
k\left(\vec{r}\cdot h\right)=-h_{s}
\]

\end_inset


\begin_inset Formula 
\[
k\left(\vec{r}\cdot\hat{h_{1}}\right)+a=0
\]

\end_inset


\begin_inset Formula 
\[
k\left(\vec{r}\cdot h_{2}\right)+b=0
\]

\end_inset

Therefore
\begin_inset Formula 
\begin{equation}
\underline{k=-\frac{h_{s}}{\vec{r}\cdot h}},\hspace{1em}a=-k\left(\vec{r}\cdot h\right)=\underline{h_{s}\frac{\vec{r}\cdot\hat{h_{1}}}{\vec{r}\cdot h}},\hspace{1em}b=\underline{h_{s}\frac{\vec{r}\cdot\hat{h_{2}}}{\vec{r}\cdot\hat{h_{0}}}}\label{eq:proj-solution}
\end{equation}

\end_inset

The image is at 
\begin_inset Formula $(a,b)$
\end_inset

 on the capturing device, typically a CCD or CMOS image sensor.
 Note that the final image shown in an video will be translated and zoomed
 according to the frame configuration.
 The final location of the pixel is 
\begin_inset Formula 
\begin{equation}
\left(a',b'\right)=\left(c_{x},c_{y}\right)+M\left(a,b\right)\label{eq:screen-zoom}
\end{equation}

\end_inset

where 
\begin_inset Formula $\left(c_{x},c_{y}\right)$
\end_inset

 are the offset of the image sensor center to the video center and 
\begin_inset Formula $M$
\end_inset

 is the zoom factor.
\end_layout

\begin_layout Standard
Note that if 
\begin_inset Formula $\vec{r}\perp\hat{h_{0}},$
\end_inset

this object is out of the FOV (field-of-view) and not on the screen.
\end_layout

\begin_layout Standard
Similarly, if 
\begin_inset Formula $\vec{r}\cdot\hat{h}_{0}<0$
\end_inset

, the object is 
\begin_inset Quotes eld
\end_inset

behind
\begin_inset Quotes erd
\end_inset

 the camera and cannot form an image.
\end_layout

\begin_layout Subsection
The bounding box of an object
\end_layout

\begin_layout Standard
Assuming the object's diameter is 
\begin_inset Formula $D$
\end_inset

, the whole shape can be approximated by a box whose vertices are given
 by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\vec{r_{i}}=\vec{r}+\left(\pm\frac{D}{2},\pm\frac{D}{2},\pm\frac{D}{2}\right)\label{eq:object-bbox}
\end{equation}

\end_inset

where 
\begin_inset Formula $1\le i\le8$
\end_inset

.
 Then for each 
\begin_inset Formula $\vec{r}_{i}$
\end_inset

, its projection on the camera screen is 
\begin_inset Formula $\vec{p}_{i}=\left(a'_{i},b'_{i}\right)$
\end_inset

, also obtained by Eq.
 (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:proj-solution"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Standard
Thus, the bounding box of the object's image is the range of the 8 projections:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
ll_{x}=\min(a'_{i}),\hspace{1em}ll_{y}=\min(b'_{i}),\hspace{1em}1\le i\le8\label{eq:image-bbox-ll}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
ur_{x}=\max(a'_{i}),\hspace{1em}ur_{y}=\max(b'_{i}),\hspace{1em}1\le i\le8\label{eq:image-bbox-ur}
\end{equation}

\end_inset

where 
\begin_inset Formula $ll$
\end_inset

, 
\begin_inset Formula $ur$
\end_inset

 denote the lower-left and upper-right corner, respectively.
 For the sake of simplicity, denote the bounding box of the object's image
 by
\begin_inset Formula 
\begin{equation}
\vec{B}=\left(\begin{array}{c}
ll_{x}\\
ll_{y}\\
ur_{x}\\
ur_{y}
\end{array}\right)=\left(\begin{array}{c}
\min a'_{i}\\
\min b'_{i}\\
\max a'_{i}\\
\max b'_{i}
\end{array}\right)\label{eq:bbox-final}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Motion model
\end_layout

\begin_layout Standard
Denote the state of an object at the time 
\begin_inset Formula $t$
\end_inset

 by 
\begin_inset Formula 
\begin{equation}
\vec{s}\left(t\right)=\left(\begin{array}{c}
\vec{r}\\
\vec{v}\\
\vec{a}
\end{array}\right)
\end{equation}

\end_inset

Then after a short time 
\begin_inset Formula $\Delta t$
\end_inset

, its state becomes
\begin_inset Formula 
\begin{equation}
\vec{s}\left(t+\Delta t\right)=\left(\begin{array}{c}
\vec{r}+\vec{v}\Delta t+\frac{1}{2}\vec{a}\left(\Delta t\right)^{2}\\
\vec{v}+\vec{a}\Delta t\\
\vec{a}+\Delta\vec{a}
\end{array}\right)
\end{equation}

\end_inset

The bounding box of its image changes to 
\begin_inset Formula 
\begin{equation}
\vec{B}\left(t\right)=f\left(\vec{r}\right)\rightarrow\vec{B}\left(t+\Delta t\right)=f\left(\vec{r}+\vec{v}\Delta t+\frac{1}{2}\vec{a}\left(\Delta t\right)^{2}\right)\label{eq:bbox-change}
\end{equation}

\end_inset

where 
\begin_inset Formula $f\left(.\right)$
\end_inset

 is the operator that maps the 3D location of an object to the bounding
 box of its image, described by Eq.
 (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:proj-solution"
plural "false"
caps "false"
noprefix "false"

\end_inset

) - (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:bbox-final"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
\end_layout

\begin_layout Section
Trajectory prediction
\end_layout

\begin_layout Standard
Given a sequence of image frames captured by a video camera, we must predict
 the trajectory of an object.
 As human or animals do, we first need to locate the object in these frames
 and then predict its next location based on its current trajectory.
 Very often, we will need to use experience on how such objects typically
 move.
 
\end_layout

\begin_layout Standard
YOLO (You Only Look Once) is a real-time object detection and image segmentation
 deep neural network (DNN) model, developed by Joseph Redmon and Ali Farhadi
 at the University of Washington
\begin_inset Foot
status open

\begin_layout Plain Layout
https://docs.ultralytics.com/
\end_layout

\end_inset

.
 Since its launch in 2015, YOLO has gained popularity for its high speed
 and accuracy.
 The latest model version is YOLOv11.
\begin_inset Foot
status open

\begin_layout Plain Layout
https://huggingface.co/Ultralytics/YOLO11
\end_layout

\end_inset

 This pre-trained model can detect 80 classes, on of which is 
\begin_inset Quotes eld
\end_inset

sports ball
\begin_inset Quotes erd
\end_inset

 (class 32).
 In this project, I use YOLOv11s to locate the bounding box of a soccer
 ball, shown in Fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:The-red-box"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename frame1.jpg
	lyxscale 30
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:The-red-box"

\end_inset

The red box is the bounding box of the soccer ball
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Assumptions
\end_layout

\begin_layout Standard
As a first-order approximation, assume that the video camera does not move,
 and that it is perfectly aligned with the world coordinate system.
 That is 
\begin_inset Formula 
\[
\left(\hat{h}_{0},\hat{h}_{1},\hat{h}_{2}\right)=\left(\begin{array}{ccc}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{array}\right)
\]

\end_inset

where the unit is meters.
 The distance of the camera screen to the optimal center (pinhole) is 
\begin_inset Formula $h_{s}=0.2$
\end_inset

 meters.
 The camera offset and zoom in Eq.
 (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:screen-zoom"
plural "false"
caps "false"
noprefix "false"

\end_inset

) are taken as 
\begin_inset Formula 
\[
\left(c_{x},c_{y}\right)=\left(0,0\right)\hspace{1em}M=1000
\]

\end_inset

These numbers are rather arbitrary, but as shown later, they have little
 effect on prediction accuracy.
\end_layout

\begin_layout Subsection
Algorithm
\end_layout

\begin_layout Standard
Given 
\begin_inset Formula $n+1$
\end_inset

 bounding boxes in the corresponding consecutive images, how do we predict
 the bounding boxes in the next 
\begin_inset Formula $m$
\end_inset

 image frames? The imaging process is illustrated in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:The-equivalent-neural"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename pasted2.png
	lyxscale 60
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:The-equivalent-neural"

\end_inset

The flow of video process, which is equivalent to a neural network
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The steps of the video process 
\end_layout

\end_body
\end_document
